# weather_kafka_pipeline
# ðŸŒ¦ End-to-End Weather Data Engineering Pipeline  

A **modern data engineering pipeline** that ingests real-time weather data using a Flask web app, streams it through Apache Kafka, stores it as JSON files (bronze layer), uploads it to **Snowflake**, and visualizes insights in **Power BI**.  
Everything runs seamlessly in **Docker** containers for easy setup and reproducibility.  

---

## ðŸ§  Project Overview  

This project demonstrates the **entire lifecycle of a data pipeline** â€” from ingestion to visualization â€” simulating a real-world streaming data workflow used in enterprise analytics.  

- ðŸŒ **Flask** â†’ serves as the API ingestion layer to fetch live weather data.  
- âš™ï¸ **Apache Kafka** â†’ acts as a distributed event-streaming platform to transmit data in real time.  
- ðŸ’¾ **Consumers** â†’ listen to Kafka topics and store JSON records locally (bronze layer).  
- â˜ï¸ **Snowflake** â†’ stores structured data for analytical processing.  
- ðŸ“Š **Power BI** â†’ visualizes the data in interactive dashboards.  

---

## ðŸ—ï¸ System Architecture  

```mermaid
flowchart TD
    A[User Input: Flask App] -->|Fetch Weather API| B[OpenWeather API]
    B -->|Send JSON| C[Kafka Producer]
    C -->|Push to Topic| D[Kafka Broker]
    D -->|Consume Messages| E[Kafka Consumer]
    E -->|Write JSON Files| F[data/bronze/ Folder]
    F -->|Watchdog + Snowflake Connector| G[Snowflake Stage]
    G -->|COPY INTO Command| H[Snowflake Weather Table]
    H -->|Live Connection| I[Power BI Dashboard]

